# **Binary Classification with PyTorch 🚀 | A Deep Dive into Neural Networks 🧠**

Welcome to a professional guide on implementing **binary classification** using **PyTorch**. This project showcases the end-to-end process of building, training, and evaluating a neural network on synthetic data, with a strong focus on visualizing results and achieving clarity in understanding.

---

## **🌟 Project Highlights**

### **🎯 Objective**  
To create a neural network capable of classifying synthetic circular data into two distinct categories with high accuracy.  

---

### **📌 Key Features**  

- **🗂 Dataset:** Synthetic concentric circles with noise for realistic challenges, generated using `scikit-learn`.  
- **🧠 Model Architecture:** Three-layer feedforward neural network with non-linear ReLU activations for learning complex patterns.  
- **📈 Results:** Achieved high accuracy with clear decision boundaries visualized pre- and post-training.  
- **🎨 Visualizations:** Training/validation loss and accuracy plots to track performance trends over epochs.

---

## **🗂 Project Structure**

1. **Dataset Creation:** Generate circular synthetic data using `make_circles` from `scikit-learn`.  
2. **Data Preprocessing:** Convert data to PyTorch tensors, split into training and test sets, and visualize.  
3. **Model Definition:** Build a feedforward network for binary classification.  
4. **Training Loop:** Implement training with backpropagation, loss calculation, and optimization using Adam.  
5. **Evaluation Metrics:** Measure accuracy and visualize decision boundaries before and after training.  
6. **Performance Visualization:** Plot accuracy and loss trends for training and test datasets.  
7. **Model Saving:** Save and reload trained models for reuse.

---

## **📊 Dataset Details**

The dataset is created using the `make_circles` function:  
- **🔄 Shape:** Two concentric circles, representing two classes.  
- **🌀 Noise:** Added noise to simulate realistic data variation.  
- **📦 Samples:** 10,000 points split into training (80%) and test (20%) datasets.  

---

## **🛠️ Model Architecture**

### **Layers**  
1. **Input Layer:** Accepts 2 features (x, y coordinates).  
2. **Hidden Layers:**  
   - First Layer: 10 neurons with ReLU activation.  
   - Second Layer: 10 neurons with ReLU activation.  
3. **Output Layer:** Single neuron with sigmoid activation for binary classification.

```python
class BinaryModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(2, 10)
        self.linear2 = nn.Linear(10, 10)
        self.linear3 = nn.Linear(10, 1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        return self.linear3(x)
```

---

## **⚙️ Training and Evaluation**

### **🎓 Training**  
- **Loss Function:** Binary Cross-Entropy with Logits (`BCEWithLogitsLoss`).  
- **Optimizer:** Adam optimizer (`lr=0.01`).  
- **Epochs:** 100 iterations over the dataset.

### **📊 Evaluation**  
- **Accuracy Metric:**  
   ```python
   def accuracy(output, labels):
       probs = torch.sigmoid(output)
       pred = (probs > 0.5).float()
       return (pred == labels).sum().item() / len(labels) * 100
   ```

- **Visualization:**  
   - **Pre-training decision boundaries.**  
   - **Post-training decision boundaries.**  
   - **Training vs Validation Loss and Accuracy trends.**  

---

## **📈 Results**

### **Final Model Performance**  
- **Train Accuracy:** ~97%  
- **Test Accuracy:** ~96%  

### **Performance Trends**  
- **Loss Curve:** Steady decline in training and validation loss over epochs.  
- **Accuracy Curve:** Consistent improvement in both training and validation accuracy.  

---

## **🔧 Getting Started**

1. **Clone the Repository:**  
   ```bash
   git clone https://github.com/JaganFoundr/Binary_Classification.git
   cd Binary_classification
   ```

2. **Install Dependencies:**  
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Training Script:**  
   ```bash
   python Binary_Classification.py
   ```

4. **Visualize Results:**  
   Access plots and decision boundaries generated by the script.

---

## **📌 Future Work**

1. **Add Dropout Layers:** Introduce dropout to mitigate overfitting.  
2. **Experiment with Optimizers:** Compare SGD and Adam for training efficiency.  
3. **Extend to Real-world Datasets:** Apply the model to practical binary classification tasks.  
4. **Explore Convolutional Networks:** Enhance learning for spatially structured data.

---

## **💡 Acknowledgments**

Special thanks to the open-source community for tools and datasets that made this project possible.

---

## **📬 Connect with Me!**  
For collaboration, ideas, or feedback, feel free to reach out!  
- **LinkedIn:** [Jagannath Harindranath](https://www.linkedin.com/in/jagannath-harindranath-492a71238/)  
- **GitHub:** [JaganFoundr](https://github.com/JaganFoundr)  

🌟 **#PyTorch #DeepLearning #AI #MachineLearning #BinaryClassification #NeuralNetworks**  
